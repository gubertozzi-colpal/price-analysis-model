# app.py
# Streamlit app: Amazon Price x BSR Analytics (multi-page)
# ‚úÖ Enterprise metadata improvement:
# - Downloadable metadata template
# - Flexible column mapping
# - Metadata validation + coverage diagnostics
# - Enrich ALL analytics with metadata fields and filters
#
# Run:
#   pip install -r requirements.txt
#   streamlit run app.py

import os
import re
import glob
from io import BytesIO
from typing import Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.ensemble import IsolationForest

# ----------------------------
# Constants / Defaults
# ----------------------------
DEFAULT_DATA_GLOB = "./dev/data/*-bsr-*.csv"
TZ = "America/Sao_Paulo"

DEFAULT_EVENTS = [
    {"name": "Prime Day 2025", "start": "2025-07-15", "end": "2025-07-16"},
    {"name": "Black Friday 2025", "start": "2025-11-28", "end": "2025-11-28"},
]

columns_map = {'ASIN': 'asin', 'Descri√ß√£o': 'sku_name'}

# Recommended metadata schema (template)
TEMPLATE_COLS = [
    "asin",          # REQUIRED
    "sku_name",      # friendly label
    "brand",
    "subbrand",
    "segment",       # e.g. Premium / Core / Entry
    "pack_type",     # Single / Pack / Multipack / Kit
    "pack_qty",      # e.g. 2, 3
    "size_ml",       # or grams
    "size_g",
    "is_own",        # 1/0 or true/false (your SKU vs competitor)
    "ean",
    "notes",
]

# Common alternative column names you might receive
CANONICAL_MAP_CANDIDATES = {
    "asin": ["asin", "ASIN", "Asin", "asin_id", "asin code", "asin_code"],
    "sku_name": ["sku_name", "sku", "name", "product_name", "title", "desc", "descricao", "description"],
    "brand": ["brand", "marca"],
    "subbrand": ["subbrand", "sub_marca", "submarca", "sub-brand"],
    "segment": ["segment", "segmento", "tier", "faixa"],
    "pack_type": ["pack_type", "pack", "promo", "tipo_pack", "tipo", "bundle_type"],
    "pack_qty": ["pack_qty", "qtd_pack", "qty", "quantidade", "pack_quantity"],
    "size_ml": ["size_ml", "ml", "volume", "tamanho_ml"],
    "size_g": ["size_g", "g", "gramas", "peso", "tamanho_g"],
    "is_own": ["is_own", "own", "meu", "is_my", "is_mine", "my_sku", "owner"],
    "ean": ["ean", "EAN", "gtin", "GTIN", "barcode", "codigo_barras"],
    "notes": ["notes", "obs", "observacao", "observa√ß√µes", "comment", "comentario"],
}

# ----------------------------
# Style CSS
# ----------------------------

st.markdown("""
    <style>
        /* Ajusta o padding inferior do container principal */
        .main .block-container {
            padding-bottom: 5rem; 
        }
        
        /* Opcional: Se o rodap√© estiver atrapalhando, voc√™ pode escond√™-lo */
        footer {
            visibility: hidden;
        }
    </style>
""", unsafe_allow_html=True)

config_export = {
    'toImageButtonOptions': {
        'format': 'png', # ou 'jpeg', 'svg', 'pdf'
        'filename': 'meu_grafico_hq',
        'height': 1080,  # Altura em pixels
        'width': 1920,   # Largura em pixels (Full HD)
        'scale': 3       # Multiplica por 3 (fica 5760x3240 - Ultra 4K)
    }
}

# ----------------------------
# Helper functions (core)
# ----------------------------
def _clean_cols(df: pd.DataFrame) -> pd.DataFrame:
    """
    Cria uma c√≥pia do DataFrame e remove espa√ßos em branco extras 
    (trim) dos nomes de todas as colunas.
    """
    df = df.copy()
    df.columns = [c.strip() for c in df.columns]
    return df


def infer_asin_from_filename(path: str) -> str:
    """
    Extrai o ASIN (Amazon Standard Identification Number) a partir do nome do arquivo.
    Tenta primeiro um padr√£o espec√≠fico ([ASIN]-bsr-1y) e, se n√£o encontrar,
    busca por qualquer sequ√™ncia de 10 caracteres alfanum√©ricos.
    """
    base = os.path.basename(path)
    # Tenta casamento com o sufixo espec√≠fico de BSR
    m = re.match(r"([A-Z0-9]{10})-bsr-1y", base)
    if m:
        return m.group(1)
    # Fallback para qualquer ASIN de 10 caracteres no nome
    m2 = re.search(r"([A-Z0-9]{10})", base)
    return m2.group(1) if m2 else base


def parse_time_col(series: pd.Series, dayfirst=True) -> pd.Series:
    """
    Converte uma coluna para datetime. Tenta converter considerando fuso hor√°rio (UTC)
    e ajustando para o fuso local (vari√°vel TZ). Se falhar (ex: formatos mistos),
    tenta uma convers√£o simples sem fuso.
    """
    dt = pd.to_datetime(series, errors="coerce", dayfirst=dayfirst, utc=True)
    try:
        dt = dt.dt.tz_convert(TZ).dt.tz_localize(None)
    except Exception:
        dt = pd.to_datetime(series, errors="coerce", dayfirst=dayfirst)
    return dt


@st.cache_data(show_spinner=False)
def load_all(data_glob: str, dayfirst=True) -> pd.DataFrame:
    """
    Carrega m√∫ltiplos arquivos CSV baseados em um padr√£o de busca (glob).
    - Extrai o ASIN do nome do arquivo.
    - Padroniza nomes de colunas essenciais (Time, Sales Rank, etc).
    - Converte tipos de dados e remove linhas sem data v√°lida.
    - Retorna um DataFrame consolidado e ordenado.
    """
    paths = sorted(glob.glob(data_glob))
    if not paths:
        return pd.DataFrame()

    all_dfs = []
    for p in paths:
        df = _clean_cols(pd.read_csv(p))
        asin = infer_asin_from_filename(p)
        df["asin"] = asin

        # Mapeamento para nomes internos padronizados
        col_map = {"Time": "time_raw", "Sales Rank": "bsr", "New Price": "price_new", "List Price": "price_list"}
        for src, dst in col_map.items():
            if src in df.columns:
                df = df.rename(columns={src: dst})
            elif dst not in df.columns:
                df[dst] = np.nan

        df["date"] = parse_time_col(df["time_raw"], dayfirst=dayfirst)
        for c in ["bsr", "price_new", "price_list"]:
            df[c] = pd.to_numeric(df[c], errors="coerce")

        df = df.dropna(subset=["date"])
        all_dfs.append(df[["asin", "date", "bsr", "price_new", "price_list"]])

    raw = pd.concat(all_dfs, ignore_index=True)
    return raw.sort_values(["asin", "date"])


@st.cache_data(show_spinner=False)
def make_daily(raw: pd.DataFrame) -> pd.DataFrame:
    """
    Transforma dados intra-di√°rios em registros di√°rios.
    - Pega o √∫ltimo valor registrado de pre√ßo e BSR no dia.
    - Define o 'price_effective' priorizando o pre√ßo novo sobre o pre√ßo de lista.
    - Cria colunas auxiliares de m√™s para agrupamentos temporais.
    """
    if raw.empty:
        return raw

    df = raw.copy()
    df["day"] = df["date"].dt.floor("D")
    daily = (
        df.sort_values(["asin", "date"])
        .groupby(["asin", "day"], as_index=False)
        .agg(
            price_new=("price_new", "last"),
            price_list=("price_list", "last"),
            price_mean=("price_new", "mean"),
            price_array=("price_new", lambda x: x.dropna().tolist()),
            bsr=("bsr", "last"),
            obs=("date", "count"), # Conta quantas observa√ß√µes originais existiam
        )
    )
    daily["price_effective"] = daily["price_new"].fillna(daily["price_list"])
    daily = daily.dropna(subset=["price_effective", "bsr"]).copy()
    daily["month"] = daily["day"].dt.to_period("M").astype(str)
    daily["month_dt"] = pd.to_datetime(daily["month"] + "-01")
    return daily


def add_base_and_promo(daily: pd.DataFrame, roll_days=30, q=0.8, promo_threshold=0.05) -> pd.DataFrame:
    """
    Identifica promo√ß√µes comparando o pre√ßo atual com um 'pre√ßo base'.
    - O pre√ßo base √© calculado usando um quantil m√≥vel (rolling quantile) de 30 dias.
    - Se o desconto em rela√ß√£o √† base for >= threshold (ex: 5%), √© marcado como promo.
    """
    df = daily.sort_values(["asin", "day"]).copy()

    # Gu: Entender como calcula por produto o pre√ßo base.
    def _base(g):
        s = g["price_effective"]
        # 1. Janela M√≥vel (Rolling)
        base_roll = s.rolling(roll_days, min_periods=max(10, roll_days // 3)).quantile(q)
        # 2. Janela Expansiva (Expanding) - O "Fallback"
        base_expand = s.expanding(min_periods=10).quantile(q)
        # 3. Combina√ß√£o
        g["price_base"] = base_roll.fillna(base_expand)
        return g

    df = df.groupby("asin", group_keys=False).apply(_base)
    df["discount_pct"] = (df["price_base"] - df["price_effective"]) / df["price_base"]
    df["discount_list_pct"] = (df["price_list"] - df["price_effective"]) / df["price_list"]
    df["is_promo"] = df["discount_pct"] >= promo_threshold
    df["rebate_value"] = df["price_base"] - df["price_effective"]
    df["price_promo"] = np.where(df["is_promo"], df["price_effective"], np.nan)
    return df


def method_corr_pivot(df: pd.DataFrame, value_col: str, method: str, id_prod: str) -> pd.DataFrame:
    """
    Calcula a correla√ß√£o de <method> entre diferentes ASINs para uma m√©trica 
    espec√≠fica (ex: pre√ßo), pivotando a tabela para ter ASINs como colunas.
    """

    columns_map = {'ASIN': 'asin', 'Descri√ß√£o': 'sku_name'}
    pivot = df.pivot(index="day", columns=columns_map[id_prod], values=value_col)
    corr = pivot.corr(method=method.lower(), min_periods=30)
    corr.index.name = id_prod
    corr.columns.name = id_prod
    return corr


def scatter_corr(df: pd.DataFrame, value_col: str, id_prod: str) -> pd.DataFrame:
    """
    Retorna um DataFrame com as datas e os valores de dois produtos espec√≠ficos,
    filtrando apenas os dias em que AMBOS possuem dados (intersec√ß√£o).
    """    
    # 1. Pivotar: O √≠ndice vira 'day' e as colunas viram os produtos
    pivot = df.pivot(index="day", columns=columns_map[id_prod], values=value_col)

    # 2. Selecionar e Resetar √çndice
    # Selecionamos as duas colunas e usamos reset_index para que 'day' volte a ser uma coluna
    df_scatter = pivot.reset_index()

    return df_scatter


def scatter_cross_corr(df: pd.DataFrame, prod1: str, prod2: str, id_prod: str) -> pd.DataFrame:
    """
    Retorna um DataFrame com 3 colunas:
    1. 'day'
    2. Coluna com nome do prod1 -> contendo PRE√áO (price_effective)
    3. Coluna com nome do prod2 -> contendo BSR (bsr)
    
    Apenas dias onde ambos t√™m dados (join='inner').
    """
    col_id = columns_map[id_prod] # Define se filtramos por 'asin' ou 'sku_name'

    # 1. Extrair S√©rie do Produto 1 (PRE√áO)
    # Filtra linhas do prod1 -> Define dia como √≠ndice -> Pega s√≥ o pre√ßo -> Renomeia a s√©rie para o nome do produto
    s1 = (
        df[df[col_id] == prod1]
        .set_index("day")["price_effective"]
        .rename(prod1)
    )

    # 2. Extrair S√©rie do Produto 2 (BSR)
    # Filtra linhas do prod2 -> Define dia como √≠ndice -> Pega s√≥ o BSR -> Renomeia
    s2 = (
        df[df[col_id] == prod2]
        .set_index("day")["bsr"]
        .rename(prod2)
    )

    # 3. Juntar as duas s√©ries (Alinhamento temporal)
    # axis=1: Coloca uma do lado da outra
    # join="inner": Mant√©m apenas os dias que existem nas DUAS s√©ries (intersec√ß√£o)
    combined = pd.concat([s1, s2], axis=1, join="inner")

    # 4. Resetar √≠ndice para ter 'day' como coluna
    return combined.reset_index()


def price_vs_bsr_corr(df: pd.DataFrame, method:str, id_prod: str) -> pd.DataFrame:
    """
    Calcula a correla√ß√£o entre Pre√ßo e BSR (Sales Rank) para cada produto.
    Ajuda a entender se a queda de pre√ßo melhora o ranking (correla√ß√£o positiva).
    """
    out = []
    columns_map = {'ASIN': 'asin', 'Descri√ß√£o': 'sku_name'}
    for asin, g in df.groupby(columns_map[id_prod]):
        n = g[["price_effective", "bsr"]].dropna().shape[0]
        # Exige ao menos 30 dias de dados para ser estatisticamente relevante
        r = g[["price_effective", "bsr"]].corr(method=method.lower()).iloc[0, 1] if n >= 30 else np.nan
        out.append({"asin": asin, "spearman_price_bsr": r, "n_obs": n})
    return pd.DataFrame(out).sort_values("spearman_price_bsr", ascending=False)


def cross_price_bsr_matrix(df: pd.DataFrame, method="spearman", id_prod='asin', min_periods=30) -> pd.DataFrame:
    """
    Gera uma matriz onde:
    - Linhas (Index) = ASIN cujo PRE√áO mudou.
    - Colunas = ASIN cujo BSR (Rank) reagiu.
    
    Exemplo de leitura: Valor na linha A, coluna B diz a correla√ß√£o entre
    o Pre√ßo de A e as Vendas (BSR) de B.
    """
    # 1. Pivotar Pre√ßos e BSRs separadamente
    # Index = Dia, Colunas = ASINs
    columns_map = {'ASIN': 'asin', 'Descri√ß√£o': 'sku_name'}
    prices = df.pivot(index="day", columns=columns_map[id_prod], values="price_effective").sort_index(axis=1)
    ranks = df.pivot(index="day", columns=columns_map[id_prod], values="bsr").sort_index(axis=1)

    # Garante que temos as mesmas colunas em ambos
    common_asins = prices.columns.intersection(ranks.columns)
    prices = prices[common_asins]
    ranks = ranks[common_asins]

    # 2. Calcular correla√ß√µes cruzadas
    # Vamos usar um loop eficiente com corrwith para comparar 
    # "Pre√ßo de Um" contra "BSR de Todos"
    matrix_data = {}
    
    for asin_driver in common_asins:
        # S√©rie de pre√ßo do "Driver"
        p_series = prices[asin_driver]
        
        # Correlaciona esse pre√ßo contra TODOS os BSRs de uma vez
        # O resultado √© uma Series com index = asin (responder)
        corrs = ranks.corrwith(p_series, method=method.lower(), drop=True)
        
        # Filtra quem n√£o tem dados suficientes (min_periods n√£o funciona direto no corrwith do jeito que queremos aqui as vezes,
        # mas o pandas lida com NaNs. Se quiser ser estrito, precisaria validar intersec√ß√£o de √≠ndices).
        matrix_data[asin_driver] = corrs

    # Monta o DataFrame final (Transposta para ficar Linha=Pre√ßo, Coluna=BSR)
    cross_matrix = pd.DataFrame(matrix_data).T
    cross_matrix.index.name = "asin_price_driver"
    cross_matrix.columns.name = "asin_bsr_responder"
    
    return cross_matrix


def price_vs_bsr_corr_kmean(df: pd.DataFrame, method:str) -> pd.DataFrame:
    """
    Calcula a correla√ß√£o entre Pre√ßo e BSR (Sales Rank) para cada produto.
    Ajuda a entender se a queda de pre√ßo melhora o ranking (correla√ß√£o positiva).
    """
    out = []
    for asin, g in df.groupby('asin'):
        n = g[["price_effective", "bsr"]].dropna().shape[0]
        # Exige ao menos 30 dias de dados para ser estatisticamente relevante
        r = g[["price_effective", "bsr"]].corr(method=method.lower()).iloc[0, 1] if n >= 30 else np.nan
        out.append({"asin": asin, "spearman_price_bsr": r, "n_obs": n})
    return pd.DataFrame(out).sort_values("spearman_price_bsr", ascending=False)


def elasticity_proxy(df: pd.DataFrame, asin: str, bucket_round=2, min_n=6) -> pd.DataFrame:
    """
    Tenta estimar a elasticidade pre√ßo-demanda (usando BSR como proxy de vendas).
    Calcula a varia√ß√£o do log do BSR em rela√ß√£o √† varia√ß√£o do pre√ßo.
    """
    g = df[df[columns_map[ctl_prod]] == asin].copy()
    if g.empty:
        return pd.DataFrame()

    b = best_price_bucket(g, min_n=min_n, bucket_round=bucket_round)
    if b.empty:
        return b

    b = b.copy().sort_values("price_bucket")
    b["log_bsr_med"] = np.log(b["bsr_median"].clip(lower=1))
    b["d_price"] = b["price_bucket"].diff()
    b["d_log_bsr"] = b["log_bsr_med"].diff()
    b["elasticity_proxy"] = (b["d_log_bsr"] / b["d_price"]).replace([np.inf, -np.inf], np.nan)
    return b


def sku_summary(df: pd.DataFrame) -> pd.DataFrame:
    """
    Gera um resumo estat√≠stico consolidado por SKU (ASIN).
    Inclui m√©dias de pre√ßo, share de promo√ß√£o e BSR mediano.
    """
    def _avg_discount_promo(x):
        # M√©dia de desconto apenas quando o item estava em promo√ß√£o
        xp = x[df.loc[x.index, "is_promo"]]
        return xp.mean() if len(xp) else np.nan

    return (
        df.groupby("asin")
        .agg(
            days=("day", "nunique"),
            avg_price=("price_effective", "mean"),
            med_price=("price_effective", "median"),
            avg_base=("price_base", "mean"),
            promo_share=("is_promo", "mean"),
            avg_discount_when_promo=("discount_pct", _avg_discount_promo),
            bsr_med=("bsr", "median"),
            bsr_mean=("bsr", "mean"),
        )
        .reset_index()
    )


def best_price_bucket(df: pd.DataFrame, min_n=6, bucket_round=2) -> pd.DataFrame:
    """
    Agrupa pre√ßos em 'baldes' (arredondados) para identificar em qual 
    faixa de pre√ßo o BSR tende a ser melhor (menor).
    """
    g = df.copy()
    g["price_bucket"] = g["price_effective"].round(bucket_round)
    agg = (
        g.groupby("price_bucket", as_index=False)
        .agg(
            n=("bsr", "size"),
            bsr_median=("bsr", "median"),
            bsr_mean=("bsr", "mean"),
            promo_share=("is_promo", "mean"),
            discount_median=("discount_pct", "median"),
        )
    )
    return agg[agg["n"] >= min_n].sort_values("bsr_median")


def build_best_prices(df: pd.DataFrame) -> pd.DataFrame:
    rows = []
    for asin, g in df.groupby("asin"):
        best = best_price_bucket(g, min_n=6)
        if len(best):
            r = best.iloc[0].to_dict()
            r["asin"] = asin
            rows.append(r)
    out = pd.DataFrame(rows)
    return out.sort_values("bsr_median") if not out.empty else out


def price_index(df: pd.DataFrame, leader_asin: str) -> pd.DataFrame:
    pivot = df.pivot(index="day", columns=columns_map[ctl_prod], values="price_effective")
    if leader_asin not in pivot.columns:
        return pd.DataFrame()
    leader = pivot[leader_asin]
    idx = pivot.divide(leader, axis=0)
    idx = idx.reset_index().melt(id_vars="day", var_name="asin", value_name="price_index")
    return idx.dropna(subset=["price_index"])


def monthly_agg(df: pd.DataFrame) -> pd.DataFrame:
    def _avg_disc_promo(x):
        xp = x[df.loc[x.index, "is_promo"]]
        return xp.mean() if len(xp) else np.nan

    return (
        df.groupby(["asin", "sku_name", "month", "month_dt"], as_index=False)
        .agg(
            price=("price_effective", "mean"),
            base=("price_base", "mean"),
            list=("price_list", "mean"),
            bsr_med=("bsr", "median"),
            bsr_mean=("bsr", "mean"),
            promo_share=("is_promo", "mean"),
            discount=("discount_pct", _avg_disc_promo),
            discount_list=("discount_list_pct", _avg_disc_promo),
        )
    )


def competitive_map(df: pd.DataFrame, k=4, random_state=42) -> pd.DataFrame:
    """
    Aplica KMeans para agrupar SKUs com comportamentos similares baseados em 
    pre√ßo, share de promo√ß√£o e sensibilidade ao BSR.
    """
    summ = sku_summary(df)
    sens = price_vs_bsr_corr_kmean(df, ctl_corr)[["asin", "spearman_price_bsr"]]
    feat = summ.merge(sens, on="asin", how="left").copy()

    # Imputa√ß√£o de nulos pela mediana para o modelo
    for c in ["avg_discount_when_promo", "spearman_price_bsr"]:
        feat[c] = feat[c].fillna(feat[c].median())

    X = feat[["avg_price", "promo_share", "avg_discount_when_promo", "bsr_med", "spearman_price_bsr"]].values
    Xs = StandardScaler().fit_transform(X) # Padroniza√ß√£o de escala
    k = max(2, min(k, len(feat)))
    km = KMeans(n_clusters=k, n_init="auto", random_state=random_state)
    feat["cluster"] = km.fit_predict(Xs)
    return feat


def event_summary(df: pd.DataFrame, start: pd.Timestamp, end: pd.Timestamp, baseline_days=14, pre=7, post=7) -> pd.DataFrame:
    win_start, win_end = start - pd.Timedelta(days=pre), end + pd.Timedelta(days=post)
    base_start, base_end = start - pd.Timedelta(days=baseline_days), start - pd.Timedelta(days=1)

    dwin = df[(df["day"] >= win_start) & (df["day"] <= win_end)]
    dbase = df[(df["day"] >= base_start) & (df["day"] <= base_end)]

    rows = []
    for asin, g in dwin.groupby("asin"):
        b = dbase[dbase["asin"] == asin]
        rows.append(
            dict(
                asin=asin,
                window_days=g["day"].nunique(),
                price_avg_window=g["price_effective"].mean(),
                promo_share_window=g["is_promo"].mean(),
                discount_avg_window=g.loc[g["is_promo"], "discount_pct"].mean(),
                bsr_med_window=g["bsr"].median(),
                bsr_mean_window=g["bsr"].mean(),
                bsr_med_baseline=b["bsr"].median() if len(b) else np.nan,
                price_avg_baseline=b["price_effective"].mean() if len(b) else np.nan,
            )
        )

    out = pd.DataFrame(rows)
    if out.empty:
        return out
    out["bsr_med_delta"] = out["bsr_med_window"] - out["bsr_med_baseline"]
    out["price_delta"] = out["price_avg_window"] - out["price_avg_baseline"]
    return out.sort_values("bsr_med_delta")


def flag_promo(df: pd.DataFrame, threshold: float = 0.05) -> pd.DataFrame:
    """
    Marca flags de promo√ß√£o (True/False) baseado em um limiar de desconto.
    - is_promo: baseado em discount_pct
    - is_promo_list: baseado em discount_list_pct
    """
    df = df.copy()

    # 1. Flag para o Desconto Efetivo
    # Verifica se a coluna existe para evitar erros
    if "discount_pct" in df.columns:
        # A compara√ß√£o vetorizada (df['col'] > x) retorna automaticamente True/False
        # fillna(False) garante que nulos n√£o virem True acidentalmente (embora a compara√ß√£o > j√° trate isso)
        df["is_promo"] = df["discount_pct"] > threshold

    # 2. Flag para o Desconto de Lista
    if "discount_list_pct" in df.columns:
        df["is_promo_list"] = df["discount_list_pct"] > threshold

    return df


def get_clean_data(df_asin: pd.DataFrame, price_col: str) -> pd.DataFrame:
    """
    Remove anomalias de BSR (ex: rupturas de estoque) usando Isolation Forest
    para garantir que o pre√ßo m√°gico n√£o seja calculado sobre dados ruidosos.
    """
    if len(df_asin) < 15:
        return df_asin
        
    # Identifica pontos que fogem da rela√ß√£o pre√ßo/bsr usual (ex: BSR alto com pre√ßo baixo)
    model = IsolationForest(contamination=0.07, random_state=42)
    preds = model.fit_predict(df_asin[[price_col, 'bsr']])
    return df_asin[preds == 1].copy()


def calculate_magic_metrics(df_asin: pd.DataFrame) -> dict:
    """
    Realiza o clustering e rotula os regimes como 'Ataque', 'Equil√≠brio' e 'Premium'.
    """
    # 1. Limpeza de dados (usando price_effective conforme discutido)
    df = get_clean_data(df_asin, price_col='price_effective')
    
    qty = df['pack_qty'].iloc[0] if 'pack_qty' in df.columns and df['pack_qty'].iloc[0] > 0 else 1
    df['unit_price'] = df['price_effective'] / qty

    # 2. Clustering
    scaler = StandardScaler()
    scaled_prices = scaler.fit_transform(df[['price_effective']])
    n_unique_prices = len(df['price_effective'].unique())
    n_clusters = min(3, n_unique_prices)
    
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    df['cluster_id'] = kmeans.fit_predict(scaled_prices)

    # 3. L√≥gica de Nomenclatura Din√¢mica
    # Calculamos o pre√ßo m√©dio de cada cluster para ordenar do mais barato ao mais caro
    cluster_order = df.groupby('cluster_id')['price_effective'].mean().sort_values().index
    
    # Mapeamento de nomes baseado na posi√ß√£o (ordem de pre√ßo)
    names = ['ü•ä Ataque', '‚öñÔ∏è Equil√≠brio', 'üíé Premium']
    mapping = {cluster_id: names[i] for i, cluster_id in enumerate(cluster_order)}
    df['regime'] = df['cluster_id'].map(mapping)

    # 4. Agrega√ß√£o Final
    summary = df.groupby('regime').agg(
        pre√ßo_m√©dio=('price_effective', 'mean'),
        pre√ßo_unit√°rio=('unit_price', 'mean'),
        bsr_mediano=('bsr', 'median'),
        amostras=('bsr', 'size')
    ).sort_values('pre√ßo_m√©dio') # Ordenado por pre√ßo para leitura f√°cil

    # O "Pre√ßo M√°gico" ainda √© o que tem o MENOR BSR
    best_regime_row = df.groupby('regime')['bsr'].median().idxmin()
    best_data = summary.loc[best_regime_row]
    
    return {
        "magic_price": best_data['pre√ßo_m√©dio'],
        "magic_unit_price": best_data['pre√ßo_unit√°rio'],
        "target_bsr": best_data['bsr_mediano'],
        "magic_regime_name": best_regime_row,
        "df_analyzed": df,
        "summary": summary
    }


def get_comparison_stats(df: pd.DataFrame, step: float, tops: list) -> pd.DataFrame:
    """Gera estat√≠sticas de BSR incluindo % de tempo em Top X din√¢mico."""
    df = df.copy()
    df['range'] = (df['price_effective'] // step) * step
    
    # Criamos colunas auxiliares para cada Top X solicitado
    # Se BSR <= limite, 1 (True), sen√£o 0 (False)
    for t in tops:
        df[f'is_top_{t}'] = (df['bsr'] <= t).astype(int)

    # Dicion√°rio de agrega√ß√£o b√°sico
    agg_dict = {
        'bsr': ['size', 'median', 'mean']
    }
    # Adicionamos a m√©dia das colunas Top X (que resultar√° na porcentagem)
    for t in tops:
        agg_dict[f'is_top_{t}'] = 'mean'
    
    stats = df.groupby('range').agg(agg_dict).reset_index()
    
    # Achatar colunas multi-√≠ndice
    stats.columns = ['range', 'days', 'rank_median', 'rank_mean'] + [f'top{t}_share' for t in tops]
    
    stats['price_range'] = stats['range'].apply(lambda x: f"R$ {x:.2f} - {x+step:.2f}")
    return stats

# ----------------------------
# METADATA: Enterprise Improvement
# ----------------------------
def make_metadata_template(asins: List[str]) -> pd.DataFrame:
    df = pd.DataFrame({"asin": asins})
    for c in TEMPLATE_COLS:
        if c not in df.columns:
            df[c] = ""
    # Put recommended columns in order
    return df[TEMPLATE_COLS]


def to_csv_bytes(df: pd.DataFrame) -> bytes:
    bio = BytesIO()
    df.to_csv(bio, index=False, encoding="utf-8-sig")
    return bio.getvalue()


def normalize_bool(s: pd.Series) -> pd.Series:
    x = s.astype(str).str.strip().str.lower()
    true_set = {"1", "true", "t", "yes", "y", "sim", "s"}
    false_set = {"0", "false", "f", "no", "n", "nao", "n√£o"}
    return x.apply(lambda v: True if v in true_set else (False if v in false_set else np.nan))


def auto_suggest_mapping(meta_cols: List[str]) -> Dict[str, Optional[str]]:
    """Best-effort mapping from meta columns to canonical template fields."""
    lower = {c.lower(): c for c in meta_cols}
    mapping = {}
    for canon, candidates in CANONICAL_MAP_CANDIDATES.items():
        chosen = None
        for cand in candidates:
            if cand.lower() in lower:
                chosen = lower[cand.lower()]
                break
        mapping[canon] = chosen
    return mapping


def apply_column_mapping(meta: pd.DataFrame, mapping: Dict[str, Optional[str]]) -> pd.DataFrame:
    """Rename mapped columns to canonical names. Keep other columns as-is."""
    meta = meta.copy()
    rename = {}
    for canon, src in mapping.items():
        if src and src in meta.columns and canon != src:
            rename[src] = canon
    meta = meta.rename(columns=rename)
    return meta


def validate_metadata(meta: pd.DataFrame, asins_in_data: List[str]) -> Tuple[pd.DataFrame, Dict[str, object]]:
    """
    Valida e limpa o arquivo de metadados enviado pelo usu√°rio.
    - Garante a presen√ßa da coluna 'asin'.
    - Remove duplicatas.
    - Normaliza colunas booleanas.
    - Gera diagn√≥sticos de cobertura (quais ASINs do dataset faltam no metadata).
    """
    diag = {"errors": [], "warnings": [], "coverage": {}}

    if meta is None or meta.empty:
        diag["warnings"].append("Nenhum metadata fornecido. O app vai rodar com nomes gen√©ricos.")
        return pd.DataFrame(), diag

    meta = _clean_cols(meta)

    if "asin" not in [c.lower() for c in meta.columns]:
        diag["errors"].append("Coluna 'asin' n√£o encontrada ap√≥s mapeamento.")
        return pd.DataFrame(), diag

    # Ensure canonical asin column name
    asin_col = None
    for c in meta.columns:
        if c.lower() == "asin":
            asin_col = c
            break
    if asin_col != "asin":
        meta = meta.rename(columns={asin_col: "asin"})

    meta["asin"] = meta["asin"].astype(str).str.strip()

    # Duplicate ASINs
    dup = meta["asin"].duplicated(keep=False)
    if dup.any():
        dups = meta.loc[dup, "asin"].value_counts().head(10).to_dict()
        diag["warnings"].append(f"ASINs duplicados no metadata (mostrando at√© 10): {dups}")
        # Keep last by default
        meta = meta.drop_duplicates("asin", keep="last")

    # Normalize is_own
    if "is_own" in meta.columns:
        meta["is_own"] = normalize_bool(meta["is_own"])

    # Guarantee minimal friendly fields
    if "sku_name" not in meta.columns:
        meta["sku_name"] = meta["asin"]
        diag["warnings"].append("Coluna 'sku_name' ausente. Usei o ASIN como nome do SKU.")
    if "brand" not in meta.columns:
        meta["brand"] = "NA"
    if "segment" not in meta.columns:
        meta["segment"] = "NA"

    # Coverage checks
    asins_set = set(asins_in_data)
    meta_set = set(meta["asin"].tolist())
    missing = sorted(list(asins_set - meta_set))
    extra = sorted(list(meta_set - asins_set))

    diag["coverage"] = {
        "asins_in_data": len(asins_set),
        "asins_in_metadata": len(meta_set),
        "mapped": len(asins_set & meta_set),
        "missing_in_metadata": len(missing),
        "extra_not_in_data": len(extra),
        "missing_list": missing[:50],  # cap
        "extra_list": extra[:50],
    }

    if missing:
        diag["warnings"].append(f"Metadata n√£o cobre {len(missing)} ASINs do dataset (mostrando at√© 50).")
    if extra:
        diag["warnings"].append(f"Metadata tem {len(extra)} ASINs que n√£o est√£o no dataset (mostrando at√© 50).")

    return meta, diag


def apply_metadata(daily: pd.DataFrame, meta: pd.DataFrame) -> pd.DataFrame:
    if meta is None or meta.empty:
        out = daily.copy()
        out["sku_name"] = out["asin"]
        out["brand"] = "NA"
        out["segment"] = "NA"
        out["is_own"] = np.nan
        return out

    out = daily.merge(meta, on="asin", how="left")
    out["sku_name"] = out.get("sku_name", out["asin"]).fillna(out["asin"])
    out["brand"] = out.get("brand", "NA").fillna("NA")
    out["segment"] = out.get("segment", "NA").fillna("NA")
    return out


def meta_filters_ui(df: pd.DataFrame) -> pd.DataFrame:
    with st.sidebar:
        with st.expander("üß© Filtros de Produto", expanded=False):

            brands = sorted(df["brand"].dropna().astype(str).unique().tolist())
            sel_brands = st.multiselect("Marca", options=brands, default=brands)

            segments = sorted(df["segment"].dropna().astype(str).unique().tolist())
            sel_segments = st.multiselect("Segmento", options=segments, default=segments)

            has_is_own = "is_own" in df.columns and df["is_own"].notna().any()
            mode = "Todos"
            if has_is_own:
                mode = st.selectbox("Tipo", ["Todos", "S√≥ meus (is_own=1)", "S√≥ concorrentes (is_own=0)"], index=0)

            q = st.text_input("Buscar SKU (nome cont√©m)", value="").strip().lower()

            asin_filter = st.text_input("Buscar ASIN (separar por v√≠rgula)", value="").strip().lower()

    f = df.copy()
    f = f[f["brand"].astype(str).isin(sel_brands)]
    f = f[f["segment"].astype(str).isin(sel_segments)]

    if has_is_own and mode != "Todos":
        f = f[f["is_own"] == ("meus" in mode.lower())]

    if q:
        f = f[f["sku_name"].astype(str).str.lower().str.contains(q, na=False)]

    if asin_filter:
        asin_list = [a.strip().lower() for a in asin_filter.split(",") if a.strip()]
        f = f[f["asin"].astype(str).str.lower().isin([x.lower() for x in asin_list])]

    return f


def filter_period(df: pd.DataFrame, min_date: pd.Timestamp, max_date: pd.Timestamp) -> pd.DataFrame:
    """Filtra o DataFrame para incluir apenas datas entre min_date e max_date (inclusivo)."""
    return df[(df["day"] >= min_date) & (df["day"] <= max_date)]


# ----------------------------
# Streamlit UI
# ----------------------------
st.set_page_config(page_title="Amazon Price x BSR Analytics", layout="wide")
st.title("üìä Amazon ‚Äì An√°lise Profissional de Pre√ßo x BSR (multi-SKU)")

with st.sidebar:
    st.header("Setup Inicial")

    st.subheader("üìÖ Controles de Data")
    min_date = st.date_input("Data inicial m√≠nima", value=pd.to_datetime("2025-01-01"))
    max_date = st.date_input("Data final m√°xima", value=pd.to_datetime("today"))

    st.subheader("üìà Controles")
    ctl_corr = st.selectbox("Tipo de Correla√ß√£o", ["Kendall", "Pearson", "Spearman"], index=2)
    ctl_prod = st.selectbox("Identificador", ["ASIN", "Descri√ß√£o"], index=1)
    freq = st.selectbox("Frequ√™ncia", ["Di√°rio", "Mensal"], index=1)

    with st.expander("üìÇ Fonte de Dados", expanded=False):
        data_glob = st.text_input("DATA_GLOB (caminho/curinga dos CSVs)", value=DEFAULT_DATA_GLOB)
        dayfirst = st.toggle("Datas no formato dia/m√™s (dayfirst)", value=True)
        st.caption("Upload de CSV + valida√ß√£o + template para baixar.")
        meta_file = st.file_uploader("Upload metadata CSV", type=["csv"])

    with st.expander('‚öôÔ∏è Configura√ß√µes',expanded=False):
        roll_days = st.slider("Janela base (dias)", 14, 60, 30, 1)
        base_q = st.slider("Quantil para base (p80 recomendado)", 0.6, 0.95, 0.8, 0.05)
        promo_threshold = st.slider("Threshold promo (% abaixo do base)", 0.02, 0.25, 0.05, 0.01)
        k_clusters = st.slider("N√∫mero de clusters", 2, 8, 4, 1)
        price_step = st.slider("Intervalo de Pre√ßo (R$)", min_value=0.1, max_value=5.0, 
                                        value=0.5, step=0.1,
                                        help="Define o tamanho do bloco de pre√ßo para a tabela comparativa.")

    
    with st.expander('üéâ Eventos',expanded=False):
        baseline_days = st.slider("Baseline antes do evento (dias)", 7, 28, 14, 1)
        pre = st.slider("Janela pr√©-evento (dias)", 0, 14, 7, 1)
        post = st.slider("Janela p√≥s-evento (dias)", 0, 14, 7, 1)

        events = st.session_state.get("events", DEFAULT_EVENTS)
        st.caption("Edite/adicione eventos (YYYY-MM-DD).")
        if st.button("‚ûï Adicionar evento"):
            events = events + [{"name": "Novo Evento", "start": "2025-01-01", "end": "2025-01-01"}]
        new_events = []
        for i, ev in enumerate(events):
            st.markdown(f"**Evento {i+1}**")
            name = st.text_input(f"Nome {i+1}", value=ev["name"], key=f"ev_name_{i}")
            start = st.text_input(f"In√≠cio {i+1}", value=ev["start"], key=f"ev_start_{i}")
            end = st.text_input(f"Fim {i+1}", value=ev["end"], key=f"ev_end_{i}")
            new_events.append({"name": name, "start": start, "end": end})
            st.divider()
        st.session_state["events"] = new_events 

    

# Load core data
raw = load_all(data_glob=data_glob, dayfirst=dayfirst)
if raw.empty:
    st.error("N√£o encontrei arquivos. Ajuste o DATA_GLOB (ex.: ./data/*-bsr-1y*.csv).")
    st.stop()

daily = add_base_and_promo(make_daily(raw), roll_days=roll_days, q=base_q, promo_threshold=promo_threshold)
asins_in_data = sorted(daily["asin"].unique().tolist())

# Metadata section (enterprise)
meta = pd.DataFrame()
diag = {"errors": [], "warnings": [], "coverage": {}}

with st.expander("üìé Metadata ‚Äì Template, Mapeamento e Valida√ß√£o", expanded=False):
    st.markdown(
        """
Aqui voc√™:
- Baixa um **template** pronto com todos os ASINs do dataset.
- Faz **upload** do metadata (pode vir com nomes de colunas diferentes).
- Ajusta um **mapeamento** (se necess√°rio).
- V√™ **valida√ß√£o e cobertura** (quantos SKUs est√£o mapeados).
        """
    )

    # Template download
    tpl = make_metadata_template(asins_in_data)
    st.download_button(
        "‚¨áÔ∏è Baixar template de metadata (com ASINs do dataset)",
        data=to_csv_bytes(tpl),
        file_name="metadata_template.csv",
        mime="text/csv",
    )

    if meta_file is not None:
        # Read metadata robustly
        file_bytes = meta_file.getvalue()
        # Try encodings
        loaded = None
        for enc in ["utf-8", "utf-8-sig", "latin1"]:
            try:
                loaded = pd.read_csv(BytesIO(file_bytes), encoding=enc, sep=';')
                break
            except Exception:
                continue
        if loaded is None:
            st.error("N√£o consegui ler seu metadata CSV. Tente salvar como UTF-8 ou UTF-8-SIG.")
        else:
            loaded = _clean_cols(loaded)

            st.markdown("**1) Mapeamento de colunas (flex√≠vel)**")
            suggested = auto_suggest_mapping(list(loaded.columns))

            cols = ["(n√£o mapear)"] + list(loaded.columns)
            mapping = {}
            c1, c2, c3 = st.columns(3)
            # show key fields first
            key_fields = ["asin", "sku_name", "brand", "segment", "is_own", "pack_type", "pack_qty", "size_ml", "size_g", "subbrand", "ean"]
            for i, canon in enumerate(key_fields):
                default = suggested.get(canon)
                idx = cols.index(default) if default in cols else 0
                target_col = (c1 if i % 3 == 0 else (c2 if i % 3 == 1 else c3)).selectbox(
                    f"{canon}  ‚Üê", options=cols, index=idx, key=f"map_{canon}"
                )
                mapping[canon] = None if target_col == "(n√£o mapear)" else target_col

            meta = apply_column_mapping(loaded, mapping)
            meta, diag = validate_metadata(meta, asins_in_data)

            # Show diagnostics
            if diag["errors"]:
                st.error("Erros no metadata:\n- " + "\n- ".join(diag["errors"]))
            if diag["warnings"]:
                st.warning("Avisos:\n- " + "\n- ".join(diag["warnings"]))

            cov = diag.get("coverage", {})
            if cov:
                st.info(
                    f"Cobertura: {cov.get('mapped',0)}/{cov.get('asins_in_data',0)} ASINs mapeados. "
                    f"Faltando no metadata: {cov.get('missing_in_metadata',0)} | "
                    f"Extras fora do dataset: {cov.get('extra_not_in_data',0)}"
                )

                if cov.get("missing_list"):
                    st.caption("ASINs do dataset sem metadata (at√© 50): " + ", ".join(cov["missing_list"]))
                if cov.get("extra_list"):
                    st.caption("ASINs no metadata que n√£o est√£o no dataset (at√© 50): " + ", ".join(cov["extra_list"]))

            st.markdown("**2) Preview do metadata (ap√≥s mapeamento/limpeza)**")
            st.dataframe(meta.head(50), width='stretch', hide_index=True)
    else:
        st.info("Opcional: fa√ßa upload do metadata para habilitar filtros por marca/segmento e insights contextualizados.")

# Apply metadata to daily and filter
daily = filter_period(daily, pd.to_datetime(min_date), pd.to_datetime(max_date))
daily = apply_metadata(daily, meta)
daily_f = meta_filters_ui(daily)

# Build artifacts on filtered data
summ = sku_summary(daily_f)
sens = price_vs_bsr_corr(daily_f, ctl_corr, ctl_prod)
summ2 = summ.merge(sens[["asin", "spearman_price_bsr"]], on="asin", how="left")
best_prices = build_best_prices(daily_f)
monthly = monthly_agg(daily_f)
price_corr = method_corr_pivot(daily_f, "price_effective",ctl_corr, ctl_prod)
bsr_corr = method_corr_pivot(daily_f, "bsr",ctl_corr, ctl_prod)
cross_corr = cross_price_bsr_matrix(daily_f, ctl_corr, ctl_prod)
scatter_price = scatter_corr(daily_f, value_col="price_effective", id_prod=ctl_prod)
scatter_bsr = scatter_corr(daily_f, value_col="bsr", id_prod=ctl_prod)
asins = sorted(daily_f[columns_map[ctl_prod]].unique().tolist())


# Tabs
pages = [
    "Vis√£o Geral",
    "Evolu√ß√£o",
    "Detalhado",
    "Correla√ß√£o",
    "Descontos",
    "√çndice de Pre√ßo",
    "Pre√ßo M√°gico",
    "Mapa Competitivo (clusters)",
    "Playbook de Eventos (Prime/Black/etc.)",
    "Recomenda√ß√µes (T√°tico & Estrat√©gico)",
    "testes",
]
tabs = st.tabs(pages)

# Utility to attach metadata into summary-like tables
def enrich_with_meta(df: pd.DataFrame) -> pd.DataFrame:
    meta_cols = [c for c in ["sku_name", "brand", "subbrand", "segment", "pack_type", "pack_qty", "size_ml", "size_g", "is_own", "ean"] if c in daily.columns]
    meta_unique = daily[["asin"] + meta_cols].drop_duplicates("asin")
    return meta_unique.merge(df, on="asin", how="right")


# Tab 1 - Vis√£o Geral
with tabs[0]:
    st.subheader("‚úÖ Vis√£o Geral (com metadata enriquecendo tudo)")
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("SKUs (filtrados)", daily_f["asin"].nunique())
    c2.metric("Per√≠odo", f"{daily_f['day'].min().date()} ‚Üí {daily_f['day'].max().date()}" if not daily_f.empty else "NA")
    c3.metric("% dias em promo (m√©dia)", f"{(daily_f.groupby('asin')['is_promo'].mean().mean()*100):.1f}%" if not daily_f.empty else "NA")
    c4.metric("BSR mediano (m√©dia)", f"{daily_f.groupby('asin')['bsr'].median().mean():.0f}" if not daily_f.empty else "NA")

    st.markdown(
        """
**T√°tico:** use filtros (marca/segmento/meus vs concorrentes) para entender ‚Äúonde est√° a guerra‚Äù agora.  
**Estrat√©gico:** estabilize pre√ßo base por segmento e defina regras de promo por cluster.
        """
    )

    color_map = {
    #True: "#0000FF",   # Verde (cor padr√£o do Plotly para 'success')
    False: "#7f7f7f"}  # Cinza escuro (neutro)}

    promo_depth = flag_promo(daily_f, promo_threshold)
    promo_depth["discount_pct"] *= 100
    promo_depth["discount_list_pct"] *= 100
    promo_depth['day'] = pd.to_datetime(promo_depth['day'])

    st.dataframe(enrich_with_meta(summ2).sort_values("bsr_med"), width='stretch', hide_index=True)

    fig2 = px.scatter(promo_depth, x="discount_pct", y="bsr", color="is_promo",
                    color_discrete_map=color_map, title=f"Profundidade (vs base) x BSR",
                    labels={"discount_pct": "Desconto vs base (%)", "bsr": "BSR"},
                    hover_data=['sku_name', 'day'])
    fig2.update_layout(xaxis=dict(range=[-100, 75]))
    fig2.update_traces(
        hovertemplate=(
            "<b>%{customdata[0]}</b><br>" +             # Nome do Produto em Negrito
            "Data: %{customdata[1]|%d/%m/%Y}<br>" +     # Data formatada BR
            "Desconto: %{x:.1f}%<br>" +                 # X com 1 casa decimal
            "BSR: %{y}" +                               # Y normal
            "<extra></extra>"                           # Remove a caixinha lateral extra
        )
    )
    st.plotly_chart(fig2, width='stretch')

    fig6 = px.scatter(promo_depth, x="discount_list_pct", y="bsr", color="is_promo_list",
                    color_discrete_map=color_map, title=f"Profundidade (vs lista) x BSR",
                    labels={"discount_list_pct": "Desconto vs lista (%)", "bsr": "BSR"},
                    hover_data=['sku_name', 'day'])
    fig6.update_layout(xaxis=dict(range=[-100, 75]))
    fig6.update_traces(
        hovertemplate=(
            "<b>%{customdata[0]}</b><br>" +             # Nome do Produto em Negrito
            "Data: %{customdata[1]|%d/%m/%Y}<br>" +     # Data formatada BR
            "Desconto: %{x:.1f}%<br>" +                 # X com 1 casa decimal
            "BSR: %{y}" +                               # Y normal
            "<extra></extra>"                           # Remove a caixinha lateral extra
        )
    )
    st.plotly_chart(fig6, width='stretch')


# Tab 2 - Evolu√ß√£o
with tabs[1]:
    st.subheader("üìà Evolu√ß√£o ‚Äì Pre√ßo e BSR")
    

    with st.expander("üìÑ Instru√ß√µes de uso", expanded=False):
        st.markdown(
            """
    **T√°tico:** comparar pre√ßo/BSR por SKU e identificar mudan√ßas abruptas.  
    **Estrat√©gico:** identificar regimes de pre√ßo (padr√µes mensais) para governan√ßa.
            """
        )


    options_full = sorted(daily_f[columns_map[ctl_prod]].dropna().unique().tolist())

    pick = st.multiselect(f"Selecione {ctl_prod}", options=options_full, default=None)

    if freq == "Mensal":

        if not pick:
            monthly = monthly.copy()

        else:
            monthly = monthly[monthly[columns_map[ctl_prod]].isin(pick)].copy()
        
        fig = px.line(monthly.sort_values("month_dt"), x="month_dt", y="price", color=columns_map[ctl_prod], 
                      markers=True, title="Pre√ßo m√©dio mensal (price_effective)")
        st.plotly_chart(fig, width='stretch')

        fig2 = px.line(monthly.sort_values("month_dt"), x="month_dt", y="bsr_med", color=columns_map[ctl_prod], 
                       markers=True, title="BSR mediano mensal (menor √© melhor)")
        st.plotly_chart(fig2, width='stretch')

        monthly_figs = monthly.groupby(["month", "month_dt"], as_index=False).agg(
            price=("price", 'median'),
            base=("base", 'median'),
            list=("list", 'median'),
            bsr=("bsr_med", "median"),
            discount=("discount", 'median'),
            discount_list=("discount_list", 'median'),
        )

        fig3 = px.line(monthly.sort_values("month_dt"), x="month_dt", y="discount", color=columns_map[ctl_prod],
                       markers=True, title="Desconto base (quando em promo√ß√£o)")
        st.plotly_chart(fig3, width='stretch')

        fig4 = px.line(monthly.sort_values("month_dt"), x="month_dt", y="discount_list",
                       color=columns_map[ctl_prod],
                       markers=True, title="Desconto lista (quando em promo√ß√£o)")
        st.plotly_chart(fig4, width='stretch')

        st.download_button("üì• Baixar dados filtrados (CSV)", data=to_csv_bytes(monthly), 
                           file_name="amazon_price_bsr_monthly.csv", mime="text/csv")


    else:
        if not pick:
            d = daily_f.copy()

        else:
            d = daily_f[daily_f[columns_map[ctl_prod]].isin(pick)].copy()

        fig = px.line(d, x="day", y="price_effective", color=columns_map[ctl_prod], 
                      title="Pre√ßo efetivo di√°rio")
        st.plotly_chart(fig, width='stretch')

        fig2 = px.line(d, x="day", y="bsr", color=columns_map[ctl_prod], 
                       title="BSR di√°rio (menor √© melhor)")
        st.plotly_chart(fig2, width='stretch')

        fig3 = px.line(d.sort_values("day"), x="day", y="discount_pct", color=columns_map[ctl_prod],
                       markers=True, title="Desconto base (quando em promo√ß√£o)")
        st.plotly_chart(fig3, width='stretch')

        fig4 = px.line(d.sort_values("day"), x="day", y="discount_list_pct",
                       color=columns_map[ctl_prod],
                       markers=True, title="Desconto lista (quando em promo√ß√£o)")
        st.plotly_chart(fig4, width='stretch')
        
        st.download_button("üì• Baixar dados filtrados (CSV)", data=to_csv_bytes(d), 
                           file_name="amazon_price_bsr_daily.csv", mime="text/csv")


# Tab 3 - Detalhado
with tabs[2]:
    st.subheader("üè∑Ô∏è Base vs Promo ‚Äì Rebaixa e Profundidade")
    with st.expander("üìÑ Instru√ß√µes de uso", expanded=False):
        st.markdown(
            """
    **T√°tico:** calibrar profundidade m√≠nima que melhora BSR.  
    **Estrat√©gico:** limitar frequ√™ncia promocional por segmento (evitar destrui√ß√£o do base).
            """
        )

    options_full = sorted(daily_f[columns_map[ctl_prod]].dropna().unique().tolist())

    a = st.selectbox(f"Selecione {ctl_prod}", options=options_full, index=0)

    g = daily_f[daily_f[columns_map[ctl_prod]] == a].copy()

    if freq == "Mensal":

        g = g.groupby(["month", "month_dt"], as_index=False).agg(
            price_effective=("price_effective", "median"),
            price_base=("price_base", "median"),
            price_list=("price_list", "median"),
            discount_pct=("discount_pct", "median"),
            discount_list_pct=("discount_list_pct", "median"),
            bsr=("bsr", "median"),
        )

        fig5 = px.bar(g.sort_values("month_dt"), x="month_dt", y="bsr")
        fig5.add_scatter(x=g["month_dt"], y=g["price_effective"], 
                         mode="lines+markers", name="Pre√ßo executado", yaxis="y2")
        
        fig5.add_scatter(x=g["month_dt"], y=g["price_base"], 
                         mode="lines+markers", name="Pre√ßo base", yaxis="y2")
        
        fig5.add_scatter(x=g["month_dt"], y=g["price_list"], 
                         mode="lines+markers", name="Pre√ßo lista", yaxis="y2")
        
        fig5.update_layout(title="Evolu√ß√£o mensal de BSR e Pre√ßo", xaxis_title="M√™s", 
                           yaxis_title="BSR mediano", yaxis2=dict(title="Pre√ßo m√©dio", 
                           overlaying='y', side='right'))
        st.plotly_chart(fig5, width='stretch', key='fig5_deta')
        
        fig = go.Figure()
        fig.add_trace(go.Scatter(x=g["month_dt"], y=g["price_effective"], mode="lines", name="Pre√ßo efetivo"))
        fig.add_trace(go.Scatter(x=g["month_dt"], y=g["price_base"], mode="lines", name="Pre√ßo base"))
        fig.add_trace(go.Scatter(x=g["month_dt"], y=g["price_list"], mode="lines", name="Pre√ßo lista"))
        fig.update_layout(title=f"Pre√ßo efetivo vs Base vs Lista - {a}", 
                          xaxis_title="M√™s", yaxis_title="Pre√ßo")
        st.plotly_chart(fig, width='stretch')

        fig2 = go.Figure()
        fig2.add_trace(go.Scatter(x=g["month_dt"], y=g["discount_pct"]*100, mode="lines", name="Desconto base"))
        fig2.add_trace(go.Scatter(x=g["month_dt"], y=g["discount_list_pct"]*100, mode="lines", name="Desconto lista"))
        fig2.update_layout(title=f"Desconto Base vs Lista - {a}", 
                          xaxis_title="M√™s", yaxis_title="Desconto (%)")
        st.plotly_chart(fig2, width='stretch')

        st.download_button("üì• Baixar dados filtrados (CSV)", data=to_csv_bytes(g),
                           file_name=f'amazon_price_bsr_monthly_{a}.csv', mime="text/csv")


    else:
        fig5 = px.bar(g.sort_values("day"), x="day", y="bsr")
        fig5.add_scatter(x=g["day"], y=g["price_effective"], 
                         mode="lines+markers", name="Pre√ßo executado", yaxis="y2")
        
        fig5.add_scatter(x=g["day"], y=g["price_base"], 
                         mode="lines+markers", name="Pre√ßo base", yaxis="y2")
        
        fig5.add_scatter(x=g["day"], y=g["price_list"], 
                         mode="lines+markers", name="Pre√ßo lista", yaxis="y2")
        
        fig5.update_layout(title="Evolu√ß√£o mensal de BSR e Pre√ßo", xaxis_title="Dia", 
                           yaxis_title="BSR mediano", yaxis2=dict(title="Pre√ßo m√©dio", 
                           overlaying='y', side='right'))
        st.plotly_chart(fig5, width='stretch', key='fig5_deta')
        
        fig = go.Figure()
        fig.add_trace(go.Scatter(x=g["day"], y=g["price_effective"], mode="lines", name="Pre√ßo efetivo"))
        fig.add_trace(go.Scatter(x=g["day"], y=g["price_base"], mode="lines", name="Pre√ßo base"))
        fig.add_trace(go.Scatter(x=g["day"], y=g["price_list"], mode="lines", name="Pre√ßo lista"))
        fig.update_layout(title=f"Pre√ßo efetivo vs Base vs Lista - {a}", 
                          xaxis_title="Dia", yaxis_title="Pre√ßo")
        st.plotly_chart(fig, width='stretch')

        fig2 = go.Figure()
        fig2.add_trace(go.Scatter(x=g["day"], y=g["discount_pct"]*100, mode="lines", name="Desconto base"))
        fig2.add_trace(go.Scatter(x=g["day"], y=g["discount_list_pct"]*100, mode="lines", name="Desconto lista"))
        fig2.update_layout(title=f"Desconto Base vs Lista - {a}", 
                          xaxis_title="Dia", yaxis_title="Desconto (%)")
        st.plotly_chart(fig2, width='stretch')

        st.download_button("üì• Baixar dados filtrados (CSV)", data=to_csv_bytes(g),
                           file_name=f'amazon_price_bsr_daly_{a}.csv', mime="text/csv")


# Tab 4 - Correla√ß√£o
with tabs[3]:
    st.subheader("üîó Correla√ß√£o ‚Äì Quem compete com quem")
    st.markdown(
        """
**T√°tico:** vigiar pares com correla√ß√£o alta para antecipar rea√ß√£o.  
**Estrat√©gico:** formar ‚Äúgrupos competitivos‚Äù por faixa/segmento.
        """
    )

    options_full = sorted(daily_f[columns_map[ctl_prod]].dropna().unique().tolist())

    col1, col2 = st.columns(2)

    with col1:
        # O primeiro controle mostra tudo
        prod_1 = st.selectbox(f"Produto A ({ctl_prod})", options=options_full)

    with col2:
        # 3. A M√°gica: Cria uma nova lista EXCLUINDO o que foi selecionado no prod_1
        options_filtered = [p for p in options_full if p != prod_1]
    
        # O segundo controle usa a lista filtrada
        prod_2 = st.selectbox(f"Produto B ({ctl_prod})", options=options_filtered)

    fig1 = px.bar(sens.sort_values("spearman_price_bsr", ascending=False),
                  x="asin", y="spearman_price_bsr",
                  title=f"Sensibilidade: {ctl_corr}(Pre√ßo, BSR)",
                  labels={"spearman_price_bsr": "Sensibilidade",
                          "asin": "Produto"})
    
    fig1.update_traces(texttemplate="%{y:.4f}", 
                       textposition="inside")
    
    fig1.update_layout(uniformtext_minsize=12, 
                       uniformtext_mode='hide')
    st.plotly_chart(fig1, width='stretch')


    fig2 = px.imshow(cross_corr, text_auto=True, aspect="auto", title=f"Correla√ß√£o {ctl_corr} Cruzada (di√°ria)")
    fig2.update_layout(yaxis_title = "Pre√ßo", xaxis_title = "BSR")
    st.plotly_chart(fig2, width='stretch')

    prod_filltered = scatter_cross_corr(daily_f, prod_1, prod_1, ctl_prod)
    prod_filltered['mes'] = prod_filltered['day'].dt.strftime('%m')
    novas_colunas = ['day', 'Pre√ßo', 'BSR', 'mes']
    prod_filltered.columns = novas_colunas
    fig_scatter = px.scatter(prod_filltered, x='Pre√ßo', y='BSR', color='mes',
                            color_discrete_sequence=px.colors.qualitative.Dark24,
                            title=f"Dispers√£o de Pre√ßo vs BSR ({prod_1})",
                            labels={prod_1: "Pre√ßo", prod_2: "BSR"},
                            hover_data={'day': '|%d/%m/%Y'})
    
    
    fig_scatter.update_traces(
    marker=dict(
        size=10,             # <--- AQUI: Tamanho do ponto (Default √© +/- 6 ou 8)
        opacity=0.7,         # Deixa meio transparente para ver sobreposi√ß√µes
        line=dict(width=1, color='DarkSlateGrey') # Contorno fininho para destacar
    ),
    hovertemplate="<b>Data: %{customdata[0]|%d/%m/%Y}</b><br>Pre√ßo: %{x}<br>BSR: %{y}<extra></extra>"
    )
    
    
    # --- AQUI EST√Å A M√ÅGICA PARA AUMENTAR AS FONTES ---
    fig_scatter.update_layout(
        # Ajusta o Eixo X (Pre√ßo)
        xaxis=dict(
            title_font=dict(size=15),  # Tamanho do t√≠tulo "Pre√ßo"
            tickfont=dict(size=20)     # Tamanho dos n√∫meros
        ),
        # Ajusta o Eixo Y (BSR)
        yaxis=dict(
            title_font=dict(size=15),  # Tamanho do t√≠tulo "BSR"
            tickfont=dict(size=20)     # Tamanho dos n√∫meros
        ),
        # Opcional: Aumentar tamb√©m o t√≠tulo do gr√°fico
        title_font=dict(size=15),

        legend_title_text='M√™s (1-12)',

        legend_title_font=dict(size=20),
        legend_font=dict(size=20)
    )

    # For√ßa a legenda a ordenar os meses (01, 02, 03...) e n√£o bagun√ßar
    fig_scatter.update_layout(legend={'traceorder': 'normal'})

    fig_scatter.update_traces(
        hovertemplate="<b>Data: %{customdata[0]|%d/%m/%Y}</b><br>Pre√ßo: %{x}<br>BSR: %{y}<extra></extra>"
    )
    st.plotly_chart(fig_scatter, width='stretch', key='teste_scatter_1', config=config_export)
    
    
    cross_filtered = scatter_cross_corr(daily_f, prod_1, prod_2, ctl_prod)
    cross_filtered['mes'] = prod_filltered['day'].dt.strftime('%m')
    fig2_scatter = px.scatter(cross_filtered, x=prod_1, y=prod_2, color='mes',
                             color_discrete_sequence=px.colors.qualitative.Dark24,
                             title=f"Dispers√£o de Pre√ßo {prod_1} vs BSR {prod_2}",
                             labels={prod_1: "Pre√ßo", prod_2: "BSR"},
                             hover_data={'day': '|%d/%m/%Y'})
    
    fig2_scatter.update_traces(
    marker=dict(
        size=10,             # <--- AQUI: Tamanho do ponto (Default √© +/- 6 ou 8)
        opacity=0.7,         # Deixa meio transparente para ver sobreposi√ß√µes
        line=dict(width=1, color='DarkSlateGrey') # Contorno fininho para destacar
    ),
    hovertemplate="<b>Data: %{customdata[0]|%d/%m/%Y}</b><br>Pre√ßo: %{x}<br>BSR: %{y}<extra></extra>"
    )

    fig2_scatter.update_layout(
        # Ajusta o Eixo X (Pre√ßo)
        xaxis=dict(
            title_font=dict(size=15),  # Tamanho do t√≠tulo "Pre√ßo"
            tickfont=dict(size=20)     # Tamanho dos n√∫meros
        ),
        # Ajusta o Eixo Y (BSR)
        yaxis=dict(
            title_font=dict(size=15),  # Tamanho do t√≠tulo "BSR"
            tickfont=dict(size=20)     # Tamanho dos n√∫meros
        ),
        # Opcional: Aumentar tamb√©m o t√≠tulo do gr√°fico
        title_font=dict(size=15),

        legend_title_text='M√™s (1-12)',

        legend_title_font=dict(size=20),
        legend_font=dict(size=20)
    )

    # For√ßa a legenda a ordenar os meses (01, 02, 03...) e n√£o bagun√ßar
    fig2_scatter.update_layout(legend={'traceorder': 'normal'})

    fig2_scatter.update_traces(
        hovertemplate="<b>Data: %{customdata[0]|%d/%m/%Y}</b><br>Pre√ßo: %{x}<br>BSR: %{y}<extra></extra>")

    st.plotly_chart(fig2_scatter, width='stretch', config=config_export, key='teste_scatter_2')
    
  
    fig3 = px.imshow(price_corr, text_auto=True, aspect="auto", title=f"Correla√ß√£o {ctl_corr} de pre√ßo (di√°ria)")
    st.plotly_chart(fig3, width='stretch')

    # Filtrar NaNs: dropna no subset dos dois produtos
    # Isso garante que s√≥ sobram dias onde prod_1 E prod_2 t√™m valores
    price_filtered = scatter_price.dropna(subset=[prod_1, prod_2])
    price_filtered['mes'] = price_filtered['day'].dt.strftime('%m')
    fig3_scatter = px.scatter(price_filtered, x=prod_1, y=prod_2, color='mes',
                             color_discrete_sequence=px.colors.qualitative.Dark24,
                             title=f"Dispers√£o de Pre√ßo: {prod_1} vs {prod_2}",
                             labels={prod_1: f"{prod_1}", prod_2: f"{prod_2}"},
                             hover_data={'day': '|%d/%m/%Y'})
    fig3_scatter.update_traces(
    marker=dict(
        size=10,             # <--- AQUI: Tamanho do ponto (Default √© +/- 6 ou 8)
        opacity=0.7,         # Deixa meio transparente para ver sobreposi√ß√µes
        line=dict(width=1, color='DarkSlateGrey') # Contorno fininho para destacar
    ),
    hovertemplate="<b>Data: %{customdata[0]|%d/%m/%Y}</b><br>Pre√ßo: %{x}<br>BSR: %{y}<extra></extra>"
    )

    fig3_scatter.update_layout(
        # Ajusta o Eixo X (Pre√ßo)
        xaxis=dict(
            title_font=dict(size=15),  # Tamanho do t√≠tulo "Pre√ßo"
            tickfont=dict(size=20)     # Tamanho dos n√∫meros
        ),
        # Ajusta o Eixo Y (BSR)
        yaxis=dict(
            title_font=dict(size=15),  # Tamanho do t√≠tulo "BSR"
            tickfont=dict(size=20)     # Tamanho dos n√∫meros
        ),
        # Opcional: Aumentar tamb√©m o t√≠tulo do gr√°fico
        title_font=dict(size=15),

        legend_title_text='M√™s (1-12)',

        legend_title_font=dict(size=20),
        legend_font=dict(size=20),

        legend={'traceorder': 'normal'}
    )


    st.plotly_chart(fig3_scatter, width='stretch', config=config_export, key='teste_scatter_3')

    fig4 = px.imshow(bsr_corr, text_auto=True, aspect="auto", title=f"Correla√ß√£o {ctl_corr} de BSR (di√°ria)")
    st.plotly_chart(fig4, width='stretch')

    # Filtrar NaNs: dropna no subset dos dois produtos
    # Isso garante que s√≥ sobram dias onde prod_1 E prod_2 t√™m valores
    bsr_filtered = scatter_bsr.dropna(subset=[prod_1, prod_2])
    bsr_filtered['mes'] = bsr_filtered['day'].dt.strftime('%m')
    fig4_scatter = px.scatter(bsr_filtered, x=prod_1, y=prod_2, color='mes',
                             color_discrete_sequence=px.colors.qualitative.Dark24,
                             title=f"Dispers√£o de BSR: {prod_1} vs {prod_2}",
                             labels={prod_1: f"{prod_1}", prod_2: f"{prod_2}"},
                             hover_data={'day': '|%d/%m/%Y'})
    
    fig4_scatter.update_traces(
    marker=dict(
        size=10,             # <--- AQUI: Tamanho do ponto (Default √© +/- 6 ou 8)
        opacity=0.7,         # Deixa meio transparente para ver sobreposi√ß√µes
        line=dict(width=1, color='DarkSlateGrey') # Contorno fininho para destacar
    ),
    hovertemplate="<b>Data: %{customdata[0]|%d/%m/%Y}</b><br>Pre√ßo: %{x}<br>BSR: %{y}<extra></extra>"
    )

    fig4_scatter.update_layout(
        # Ajusta o Eixo X (Pre√ßo)
        xaxis=dict(
            title_font=dict(size=15),  # Tamanho do t√≠tulo "Pre√ßo"
            tickfont=dict(size=20)     # Tamanho dos n√∫meros
        ),
        # Ajusta o Eixo Y (BSR)
        yaxis=dict(
            title_font=dict(size=15),  # Tamanho do t√≠tulo "BSR"
            tickfont=dict(size=20)     # Tamanho dos n√∫meros
        ),
        # Opcional: Aumentar tamb√©m o t√≠tulo do gr√°fico
        title_font=dict(size=15),

        legend_title_text='M√™s (1-12)',

        legend_title_font=dict(size=20),
        legend_font=dict(size=20),
        legend={'traceorder': 'normal'}
    )

    st.plotly_chart(fig4_scatter, width='stretch', config=config_export, key='teste_scatter_4')


# Tab 5 - Desconto
with tabs[4]:
    st.subheader("üè∑Ô∏è Impacto de Descontos")

    promo_depth = daily_f.copy()

    fig4 = px.box(promo_depth, x=columns_map[ctl_prod], y=np.log(promo_depth["bsr"]),
                  title="Distribui√ß√£o de profundidade promocional (% vs base)", 
                  labels={"y": "BSR"})
    st.plotly_chart(fig4, width='stretch')

    fig5 = px.box(promo_depth, x=columns_map[ctl_prod], y=promo_depth["price_effective"],
                  title="Distribui√ß√£o de profundidade promocional (% vs base)", 
                  labels={"y": "Pre√ßo"})
    st.plotly_chart(fig5, width='stretch')

    fig3 = px.box(promo_depth, x=columns_map[ctl_prod], y=promo_depth["discount_pct"] * 100,
                  title="Distribui√ß√£o de profundidade promocional (% vs base)", 
                  labels={"y": "% desconto vs base"})
    st.plotly_chart(fig3, width='stretch')


# Tab 6 - √çndice de Pre√ßo
with tabs[5]:
    st.subheader("üìå √çndice de Pre√ßo (Price Index)")
    st.markdown(
        """
**T√°tico:** gatilhos de ajuste via √≠ndice vs refer√™ncia.  
**Estrat√©gico:** arquitetura premium/core/entry com √≠ndices consistentes.
        """
    )

    # if metadata includes is_own, offer pool selection
    leader_pool = asins
    if "is_own" in daily_f.columns and daily_f["is_own"].notna().any():
        leader_mode = st.radio("Escolher refer√™ncia entre:", ["Todos", "S√≥ concorrentes (is_own=0)", "S√≥ meus (is_own=1)"], horizontal=True)
        if "concorrentes" in leader_mode.lower():
            leader_pool = sorted(daily_f.loc[daily_f["is_own"] == False, "asin"].unique().tolist()) or asins
        elif "meus" in leader_mode.lower():
            leader_pool = sorted(daily_f.loc[daily_f["is_own"] == True, "asin"].unique().tolist()) or asins

    leader = st.selectbox("Escolha o SKU refer√™ncia (l√≠der)", options=leader_pool, index=0)
    idx = price_index(daily_f, leader_asin=leader)

    if idx.empty:
        st.warning("N√£o consegui montar √≠ndice (verifique se o l√≠der tem pre√ßo para as datas).")
    else:
        if freq == "Mensal":
            idx_m = idx.copy()
            idx_m["month_dt"] = idx_m["day"].dt.to_period("M").dt.to_timestamp()
            idx_m = idx_m.groupby(["asin", "month_dt"], as_index=False)["price_index"].mean()
            fig = px.line(idx_m, x="month_dt", y="price_index", color="asin", title=f"√çndice de pre√ßo mensal vs {leader}")
            fig.add_hline(y=1.0, line_dash="dash", annotation_text="Refer√™ncia = 1.0")
            st.plotly_chart(fig, width='stretch')
        else:
            fig = px.line(idx, x="day", y="price_index", color="asin", title=f"√çndice de pre√ßo di√°rio vs {leader}")
            fig.add_hline(y=1.0, line_dash="dash", annotation_text="Refer√™ncia = 1.0")
            st.plotly_chart(fig, width='stretch')


# Tab 7 - Pre√ßo M√°gico
with tabs[6]:
    st.subheader("‚ú® Intelig√™ncia de Pre√ßo M√°gico")
    st.markdown(
        """
 Identifica√ß√£o autom√°tica de 'Pre√ßos de Ataque' e regimes de competitividade via ML.
**T√°tico:** definir ‚Äúpre√ßo de ataque‚Äù por SKU/segmento.  
**Estrat√©gico:** escada de promo e governan√ßa por cluster.
        """
    )
    col_a, col_b = st.columns(2)
    with col_a:
        selected_a = st.selectbox("Produto A (Principal)", options=asins, key="magic_selector")
    with col_b:
        # Filtra asins para n√£o selecionar o mesmo no B (opcional)
        options_b = [opt for opt in asins if opt != selected_a]
        selected_b = st.selectbox("Produto B (Comparativo)", options=options_b, key="bench_selector")

    # --- ABA: PRE√áO M√ÅGICO ---
    st.markdown("Identifica√ß√£o autom√°tica de 'Pre√ßos de Ataque' e regimes de competitividade via ML.")

    # 1. Gera√ß√£o de Relat√≥rio Consolidado (Download)
    all_magic_results = []
    for asin_code in asins:
        sku_subset = daily_f[daily_f[columns_map[ctl_prod]] == asin_code]
        if len(sku_subset) > 10:
            res = calculate_magic_metrics(sku_subset)
            all_magic_results.append({
                "asin": asin_code,
                "sku_name": sku_subset['sku_name'].iloc[0] if 'sku_name' in sku_subset.columns else asin_code,
                "pre√ßo_m√°gico_pack": res['magic_price'],
                "pre√ßo_m√°gico_unit√°rio": res['magic_unit_price'],
                "bsr_alvo": res['target_bsr'],
                "confian√ßa_dados": res['summary']['amostras'].sum()
            })
        
    # 2. Detalhamento Visual por SKU
    sku_history = daily_f[daily_f[columns_map[ctl_prod]] == selected_a].copy()

    if len(sku_history) > 10:
        magic_res = calculate_magic_metrics(sku_history)
        df_plot = magic_res["df_analyzed"]
        
        # KPIs R√°pidas
        kpi1, kpi2, kpi3 = st.columns(3)
        kpi1.metric("Pre√ßo M√°gico (Pack)", f"R$ {magic_res['magic_price']:.2f}")
        kpi2.metric("Pre√ßo p/ Unidade", f"R$ {magic_res['magic_unit_price']:.2f}")
        kpi3.metric("BSR Mediano Alvo", int(magic_res['target_bsr']))


        # Tabela Detalhada
        with st.expander("Ver detalhes estat√≠sticos dos regimes"):
            st.table(magic_res["summary"])
    

        # Gr√°fico de Regimes e Tend√™ncia
        st.write("#### Curva de Performance e Regimes Identificados")
        fig_magic = px.scatter(
                df_plot, 
                x="price_effective", # Usando o pre√ßo efetivo
                y="bsr", 
                color="regime", # Agora aparecer√° 'Ataque', 'Equil√≠brio', etc.
                color_discrete_map={
                    'ü•ä Ataque': '#00CC96',     # Verde
                    '‚öñÔ∏è Equil√≠brio': '#636EFA',   # Azul
                    'üíé Premium': '#EF553B'      # Vermelho
                },
                title=f"An√°lise de Regimes de Pre√ßo - {selected_a}",
                labels={"price_effective": "Pre√ßo Final", 
                        "bsr": "Ranking (BSR)", "regime": "Estrat√©gia"},
                trendline="lowess"
            )
        st.plotly_chart(fig_magic, width='stretch')

        # Histograma de Efici√™ncia Unit√°ria
        st.write("#### Sensibilidade por Pre√ßo Unit√°rio")
        # Criando o histograma
        fig_unit_hist = px.histogram(
            df_plot, 
            x="price_effective", 
            y="bsr", 
            histfunc="avg", 
            nbins=15,
            title=f"üìä Sensibilidade: BSR M√©dio por Pre√ßo Unit√°rio",
            color_discrete_sequence=['#83C9FF']
        )

        # 1. Configurando o Hover (Texto ao passar o mouse)
        fig_unit_hist.update_traces(
            hovertemplate="<br>".join([
                "<b>Faixa de Pre√ßo Unit.:</b> R$ %{x:.2f}",
                "<b>BSR M√©dio:</b> %{y:.0f}",
                "<extra></extra>" # Remove a legenda lateral de 'trace 0'
            ])
        )

        # 2. Configurando Eixos e Layout
        fig_unit_hist.update_layout(
            xaxis_title="Pre√ßo Final",
            yaxis_title="BSR M√©dio",
            hovermode="x unified", # Facilita a leitura ao alinhar o hover com o eixo X
            bargap=0.1,            # Adiciona um pequeno espa√ßamento entre as barras para legibilidade
            plot_bgcolor="rgba(0,0,0,0)", # Fundo transparente para combinar com o tema do Streamlit
        )

        # 3. Ajustando grades dos eixos para um visual mais limpo
        fig_unit_hist.update_xaxes(showgrid=False, tickprefix="R$ ")
        fig_unit_hist.update_yaxes(showgrid=True, gridcolor='LightGray')

        st.plotly_chart(fig_unit_hist, width='stretch')


    else:
        st.info("Este SKU ainda n√£o possui hist√≥rico suficiente para an√°lise de Machine Learning.")
    

    st.write("#### üìä Performance e Ranquing Share")
    st.markdown("Configure os limites de **Top Rank** para ver a domin√¢ncia em cada faixa de pre√ßo:")

    # Inputs Din√¢micos para os "Top X"
    c1, c2, c3 = st.columns(3)
    with c1:
        top_val1 = st.number_input("Limite 1 (Top X)", value=10, step=5, key="t1")
    with c2:
        top_val2 = st.number_input("Limite 2 (Top X)", value=20, step=5, key="t2")
    with c3:
        top_val3 = st.number_input("Limite 3 (Top X)", value=50, step=5, key="t3")

    list_tops = [top_val1, top_val2, top_val3]

    # Processamento com os novos limites
    data_a = daily_f[daily_f[columns_map[ctl_prod]] == selected_a]
    data_b = daily_f[daily_f[columns_map[ctl_prod]] == selected_b]
    stats_a = get_comparison_stats(data_a, price_step, list_tops)
    stats_b = get_comparison_stats(data_b, price_step, list_tops)

    # Merge dos dados
    comparison_df = pd.merge(
        stats_a, stats_b, on="price_range", how="outer", suffixes=('_A', '_B')
    ).sort_values("range_A").fillna(0)

    # Formata√ß√£o de Porcentagem para as colunas de Share
    cols_to_format = [f'top{t}_share_A' for t in list_tops] + [f'top{t}_share_B' for t in list_tops]
    for col in cols_to_format:
        comparison_df[col] = (comparison_df[col] * 100).map("{:.1f}%".format)

    # Definindo a fun√ß√£o de estilo para a coluna de pre√ßo
    def style_price_col(df):
        # Criamos um DataFrame de estilos vazio
        style_df = pd.DataFrame('', index=df.index, columns=df.columns)
        
        # Aplicamos a cor escura na coluna de 'Price Range'
        # 'background-color: #262730' √© um cinza escuro que combina com o tema dark do Streamlit
        style_df['Price Range'] = 'background-color: #1E1E1E; color: #D1D1D1; font-weight: bold; border-right: 1px solid #444;'
        
        return style_df

    # 1. Preparamos o DataFrame final sem as colunas de range
    df_final = comparison_df.drop(columns=['range_A', 'range_B'])

    # 2. Pegamos o nome exato da primeira coluna (para evitar o KeyError)
    coluna_pre√ßo = df_final.columns[6] 

    # 3. Aplicamos o estilo usando o nome din√¢mico
    styled_comparison = df_final.style.set_properties(**{
        'background-color': '#1E1E1E',
        'color': '#D1D1D1',
        'font-weight': 'bold',
        'border-right': '1px solid #444'
    }, subset=[coluna_pre√ßo]) 

    # 4. Formata√ß√µes num√©ricas din√¢micas (ajustado para os nomes que voc√™ deu no merge)
    # Se voc√™ renomeou as colunas manualmente antes, garanta que os nomes aqui batam
    format_dict = {}
    for col in df_final.columns:
        if 'rank_median_A' in col or 'rank_median_b' in col: format_dict[col] = '{:.0f}'
        if 'rank_mean_A' in col or 'rank_mean_B' in col: format_dict[col] = '{:.1f}'
        if 'days_A' in col or 'days_B' in col: format_dict[col] = '{:.0f}'

    styled_comparison = styled_comparison.format(format_dict)

    # 5. Renderiza√ß√£o
    st.dataframe(styled_comparison, use_container_width=True, hide_index=True)
            
    if all_magic_results:
        df_export = pd.DataFrame(all_magic_results)
        csv_data = df_export.to_csv(index=False).encode('utf-8')

    st.download_button(
            label="üì• Baixar Estrat√©gia de Pricing (CSV)",
            data=csv_data,
            file_name='relatorio_preco_magico.csv',
            mime='text/csv',
            help="Exporta o pre√ßo m√°gico sugerido para todos os SKUs da base."
        )


# Tab 8
with tabs[7]:
    st.subheader("üó∫Ô∏è Mapa Competitivo (clusters) ‚Äì enriquecido com metadata")
    st.markdown(
        """
**T√°tico:** enxergar quem √© agressivo em promo e onde voc√™ precisa reagir.  
**Estrat√©gico:** pol√≠tica por cluster (premium/core/entry).
        """
    )

    comp = competitive_map(daily_f, k=k_clusters)
    comp = enrich_with_meta(comp)
    st.dataframe(comp.sort_values(["cluster", "avg_price"]), width='stretch', hide_index=True)

    hover_cols = [c for c in ["asin", "sku_name", "brand", "segment", "pack_type", "pack_qty", "size_ml", "size_g", "is_own", "bsr_med", "spearman_price_bsr"] if c in comp.columns]
    fig = px.scatter(
        comp,
        x="avg_price",
        y="promo_share",
        color="cluster",
        size="avg_discount_when_promo",
        hover_data=hover_cols,
        title="Mapa: Pre√ßo m√©dio vs % dias em promo (tamanho = profundidade m√©dia em promo)",
        labels={"avg_price": "Pre√ßo m√©dio", "promo_share": "% dias em promo"},
    )
    st.plotly_chart(fig, width='stretch')


# Tab 9
with tabs[8]:
    st.subheader("üéØ Playbook de Eventos ‚Äì com leitura por metadata")
    st.markdown(
        """
**T√°tico:** replicar profundidade/dura√ß√£o que trouxe ŒîBSR melhor.  
**Estrat√©gico:** escolher SKUs ‚Äúhero‚Äù por evento e segmentar investimento.
        """
    )

    for ev in st.session_state["events"]:
        try:
            s = pd.to_datetime(ev["start"])
            e = pd.to_datetime(ev["end"])
        except Exception:
            st.warning(f"Evento com data inv√°lida: {ev}")
            continue

        st.markdown(f"### {ev['name']} ({ev['start']} ‚Üí {ev['end']})")
        es = event_summary(daily_f, s, e, baseline_days=baseline_days, pre=pre, post=post)
        if es.empty:
            st.info("Sem dados nesse per√≠odo.")
            continue

        es = enrich_with_meta(es)
        st.dataframe(es, width='stretch', hide_index=True)

        fig = px.bar(es.sort_values("bsr_med_delta"), x="asin", y="bsr_med_delta",
                     title="Œî BSR mediano (janela - baseline) ‚Äî negativo = melhorou")
        fig.add_hline(y=0, line_dash="dash")
        st.plotly_chart(fig, width='stretch')

        color_col = "is_own" if ("is_own" in es.columns and es["is_own"].notna().any()) else None
        fig2 = px.scatter(
            es,
            x="price_delta",
            y="bsr_med_delta",
            size="promo_share_window",
            color=color_col,
            hover_data=[c for c in ["sku_name", "brand", "segment", "discount_avg_window", "bsr_med_baseline", "bsr_med_window"] if c in es.columns],
            title="Trade-off ŒîPre√ßo vs ŒîBSR (tamanho = % dias em promo na janela)",
        )
        fig2.add_hline(y=0, line_dash="dash")
        fig2.add_vline(x=0, line_dash="dash")
        st.plotly_chart(fig2, width='stretch')


# Tab 10
with tabs[9]:
    st.subheader("üß† Recomenda√ß√µes (T√°tico & Estrat√©gico) ‚Äì contextualizadas")
    st.markdown(
        """
As recomenda√ß√µes aqui respeitam o **filtro atual** (marca/segmento/meus vs concorrentes).  
Isso √© perfeito para reuni√µes de categoria: voc√™ troca o filtro e o plano muda na hora.
        """
    )

    gov = enrich_with_meta(summ2).copy()
    gov["promo_share_pct"] = gov["promo_share"] * 100
    gov["avg_discount_promo_pct"] = gov["avg_discount_when_promo"] * 100

    st.markdown("### 1) Onde promo tende a funcionar melhor (sensibilidade pre√ßo‚ÜíBSR)")
    sens_rank = sens.dropna(subset=["spearman_price_bsr"]).sort_values("spearman_price_bsr", ascending=False)
    if len(sens_rank):
        top = sens_rank.head(5)["asin"].tolist()
        top_named = enrich_with_meta(pd.DataFrame({"asin": top})).merge(sens_rank, on="asin", how="left")
        st.dataframe(top_named, width='stretch', hide_index=True)
    else:
        st.info("Sem dados suficientes para ranquear sensibilidade no recorte filtrado.")

    st.markdown("### 2) Governan√ßa de promo (frequ√™ncia e profundidade)")
    show_cols = [c for c in ["asin","sku_name","brand","segment","is_own","avg_price","promo_share_pct","avg_discount_promo_pct","bsr_med","spearman_price_bsr"] if c in gov.columns]
    st.dataframe(gov[show_cols].sort_values("promo_share_pct", ascending=False), width='stretch', hide_index=True)

    st.markdown("### 3) Sugest√µes de ‚Äòpre√ßo de ataque‚Äô (pre√ßo m√°gico)")
    if best_prices.empty:
        st.info("Sem c√°lculo robusto de pre√ßo m√°gico no recorte filtrado (poucos buckets repetidos).")
    else:
        st.dataframe(enrich_with_meta(best_prices), width='stretch', hide_index=True)

    st.markdown("### 4) Checklist t√°tico (semana)")
    st.markdown(
        """
- **Alerta de guerra de pre√ßo:** observe pares com correla√ß√£o alta (aba Correla√ß√£o).
- **Guardrails por segmento:** limite % dias em promo e defina 2‚Äì3 degraus de profundidade.
- **Pre√ßo de ataque:** use ‚Äòpre√ßo m√°gico‚Äô + ‚Äòeventos‚Äô como refer√™ncia m√≠nima.
- **Evitar over-promo:** se promo_share sobe e BSR n√£o melhora, pare e reavalie (prov√°vel driver fora de pre√ßo).
        """
    )


# Tab 11 - Teste
with tabs[10]:
    st.subheader("üß™ Testes")


st.caption("App de an√°lise Pre√ßo x BSR com metadata enterprise (template + mapeamento + valida√ß√£o + cobertura).")
